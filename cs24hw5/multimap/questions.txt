Multimap Caching Performance
============================

a)  Size of hardware cache lines:
L1: 64B
L2: 64B
L3: 64B


b)  Output of mmperf:
This program measures multimap read performance by doing the following, for
various kinds of usage patterns:

 * First, a large number of randomly generated (key, value) pairs are inserted
   into an empty multimap.

 * Next, more (key, value) pairs are randomly generated, and the multimap is
   probed to see if each pair is in the map.  The amount of wall-clock time
   taken for this step is measured and used to estimate the time-per-probe
   of the map.

 * Finally, the program prints out how many of the generated (key, value) pairs
   were in the map.  This number should not change regardless of optimizations
   to the data structure, because the same random seed is always used at the
   start of the program.

Testing multimap performance:  300000 pairs, 1000000 probes, random keys.
Adding 300000 randomly generated pairs to multimap.
Keys in range [0, 50), values in range [0, 1000).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 50), values in range [0, 1000).
997144 out of 1000000 test-pairs were in the map (99.7%)
Total wall-clock time:  32.61 seconds		μs per probe:  32.613 μs

Testing multimap performance:  300000 pairs, 1000000 probes, incrementing keys.
Adding 300000 randomly generated pairs to multimap.
Keys in range [0, 50), values in range [0, 1000).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 50), values in range [0, 1000).
997715 out of 1000000 test-pairs were in the map (99.8%)
Total wall-clock time:  68.15 seconds		μs per probe:  68.149 μs

Testing multimap performance:  300000 pairs, 1000000 probes, decrementing keys.
Adding 300000 randomly generated pairs to multimap.
Keys in range [0, 50), values in range [0, 1000).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 50), values in range [0, 1000).
997325 out of 1000000 test-pairs were in the map (99.7%)
Total wall-clock time:  69.09 seconds		μs per probe:  69.092 μs

Testing multimap performance:  15000000 pairs, 1000000 probes, random keys.
Adding 15000000 randomly generated pairs to multimap.
Keys in range [0, 100000), values in range [0, 50).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 100000), values in range [0, 50).
949586 out of 1000000 test-pairs were in the map (95.0%)
Total wall-clock time:  8.09 seconds		μs per probe:  8.092 μs

Testing multimap performance:  100000 pairs, 50000 probes, incrementing keys.
Adding 100000 randomly generated pairs to multimap.
Keys in range [0, 100000), values in range [0, 50).
Probing multimap 50000 times with randomly generated test-pairs.
Keys in range [0, 100000), values in range [0, 50).
976 out of 50000 test-pairs were in the map (2.0%)
Total wall-clock time:  208.16 seconds		μs per probe:  4163.128 μs

Testing multimap performance:  100000 pairs, 50000 probes, decrementing keys.
Adding 100000 randomly generated pairs to multimap.
Keys in range [0, 100000), values in range [0, 50).
Probing multimap 50000 times with randomly generated test-pairs.
Keys in range [0, 100000), values in range [0, 50).
980 out of 50000 test-pairs were in the map (2.0%)
Total wall-clock time:  204.62 seconds		μs per probe:  4092.388 μs

c)  Explanation of tests:
The first three have a smaller key range, and larger value range, wheras the
last three tests have a larger key range, and a smaller value range. This
represents multimaps that either have more keys and less linked lists off of
each key (in the second case), whereas the first case represents multimaps
where there are less keys but there were larger and longer linked lists
connected to each key. This means that the first one is more testing
cycling through linked lists on the tree, and the second one is testing
iterating through the structure of the tree itself. We can see from our
time outputs that moving through the tree in our cache is more time consuming
than navigating through the linked lists.

e)  Explanation of your optimizations:

Change 1:
The first change that I implemented was that I changed the structure of the
list of values connected to each node in the multi map. This structure was
initially a linked list, but we changed it to be a simple array, which would
be contagious in memory instead of not contagious in the linked list. A linked
list will be randomly placed, which will give us more conflict misses which
will ultimately slow down how long it takes us to access memory. When the
values of the array are read and written too, they can be cached with fewer
caches because they are closer together in memory than the linked list. This
array is continuous thus improves the locality of the linked list. Our array
also was when we were adding values into the value list, we used realloc to
free more memory after each value was added, which enforced that our
array of values for each key would be in the same location.

Change 2:
The second change that I implemented will influence the results of test4-6.
This is because I will be addressing the locality of the nodes in the tree.
In order to do this, I implemented a technique referred to as "slab allocation".
This method allocates a chunk of space for a group of nodes, and then after
that many nodes were created, and that chunk of space was filled by nodes,
I moved the pointer to a newly freed chunk of space. The nodes in that chunk
of space is then thus accsessed by locating the given node that is at the head
of that chunk. This method makes our program more cache-friendly because
the nodes that are in memory closer together, which once again improves the
cache locality so it is easier for our cache to accsess. This means that the
nodes of our tree can be found in the same cache block as each other and thus
makes our program more cache friendly.



f)  Output of ommperf:
This program measures multimap read performance by doing the following, for
various kinds of usage patterns:

 * First, a large number of randomly generated (key, value) pairs are inserted
   into an empty multimap.

 * Next, more (key, value) pairs are randomly generated, and the multimap is
   probed to see if each pair is in the map.  The amount of wall-clock time
   taken for this step is measured and used to estimate the time-per-probe
   of the map.

 * Finally, the program prints out how many of the generated (key, value) pairs
   were in the map.  This number should not change regardless of optimizations
   to the data structure, because the same random seed is always used at the
   start of the program.

Testing multimap performance:  300000 pairs, 1000000 probes, random keys.
Adding 300000 randomly generated pairs to multimap.
Keys in range [0, 50), values in range [0, 1000).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 50), values in range [0, 1000).
997144 out of 1000000 test-pairs were in the map (99.7%)
Total wall-clock time:  0.47 seconds		μs per probe:  0.473 μs

Testing multimap performance:  300000 pairs, 1000000 probes, incrementing keys.
Adding 300000 randomly generated pairs to multimap.
Keys in range [0, 50), values in range [0, 1000).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 50), values in range [0, 1000).
997715 out of 1000000 test-pairs were in the map (99.8%)
Total wall-clock time:  0.50 seconds		μs per probe:  0.496 μs

Testing multimap performance:  300000 pairs, 1000000 probes, decrementing keys.
Adding 300000 randomly generated pairs to multimap.
Keys in range [0, 50), values in range [0, 1000).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 50), values in range [0, 1000).
997325 out of 1000000 test-pairs were in the map (99.7%)
Total wall-clock time:  0.53 seconds		μs per probe:  0.526 μs

Testing multimap performance:  15000000 pairs, 1000000 probes, random keys.
Adding 15000000 randomly generated pairs to multimap.
Keys in range [0, 100000), values in range [0, 50).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 100000), values in range [0, 50).
949586 out of 1000000 test-pairs were in the map (95.0%)
Total wall-clock time:  0.77 seconds		μs per probe:  0.768 μs

Testing multimap performance:  100000 pairs, 50000 probes, incrementing keys.
Adding 100000 randomly generated pairs to multimap.
Keys in range [0, 100000), values in range [0, 50).
Probing multimap 50000 times with randomly generated test-pairs.
Keys in range [0, 100000), values in range [0, 50).
976 out of 50000 test-pairs were in the map (2.0%)
Total wall-clock time:  8.07 seconds		μs per probe:  161.438 μs

Testing multimap performance:  100000 pairs, 50000 probes, decrementing keys.
Adding 100000 randomly generated pairs to multimap.
Keys in range [0, 100000), values in range [0, 50).
Probing multimap 50000 times with randomly generated test-pairs.
Keys in range [0, 100000), values in range [0, 50).
980 out of 50000 test-pairs were in the map (2.0%)
Total wall-clock time:  7.87 seconds		μs per probe:  157.410 μs
